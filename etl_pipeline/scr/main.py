import sys
import os
import logging
from pathlib import Path

CURRENT_DIR = Path(__file__).resolve().parent
if str(CURRENT_DIR) not in sys.path:
    sys.path.insert(0, str(CURRENT_DIR))

from dotenv import load_dotenv
load_dotenv()

from extract import extract_data
from transform.text import(
    normalize_text_columns,
    normalize_text_data,
    clean_text_data
)
from transform.numeric import(
    clean_numeric_data,
    fill_nan_numeric_data,
    round_metrics
)
from validation import(
    validate_columns,
    validate_registers_count,
    nulls_year_column,
    validate_regions,
    validate_country_count,
    generation_without_instaled_capacity,
    validate_composed_key
)
from config import check_connection
from load import load_data


BASE_DIR = Path(__file__).resolve().parent.parent
OUTPUT_DIR = BASE_DIR / 'data' / 'processed'

LOG_DIR = BASE_DIR / 'data' / 'logs'
LOG_DIR.mkdir(parents=True, exist_ok=True)


logging.basicConfig(
    level = logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    handlers=[
        logging.FileHandler(LOG_DIR / "etl.log", mode="a", encoding="utf-8"),
        logging.StreamHandler()
    ]
)


logger = logging.getLogger(__name__)


def run_pipeline():

    logger.info("="*60)
    logger.info("PIPELINE ETL - RENEWABLE ENERGY DATA")
    logger.info("="*60)

    try:

        logger.info("üîå Verificando conex√£o com o Data Warehouse...")
        if not check_connection():
            raise ConnectionError("N√£o foi poss√≠vel conectar ao banco de dados.")

        logger.info("\nüì• ETAPA 1/6: EXTRA√á√ÉO")
        df = extract_data()

        logger.info("\nüìù ETAPA 2/6: TRANSFORMA√á√ïES TEXTUAIS")
        df = normalize_text_columns(df)
        df = normalize_text_data(df)
        df = clean_text_data(df)

        logger.info("\nüî¢ ETAPA 3/6: TRANSFORMA√á√ïES NUM√âRICAS")
        df = clean_numeric_data(df)
        df = fill_nan_numeric_data(df)
        df = round_metrics(df)

        logger.info("\nüîç ETAPA 4/6: VALIDA√á√ÉO")
        df = validate_columns(df)
        df = validate_registers_count(df)
        df = nulls_year_column(df)
        df = validate_regions(df)
        df = validate_country_count(df)
        df = generation_without_instaled_capacity(df)
        df = validate_composed_key(df)
    
        logger.info("\nüíæ ETAPA 5/6 SALVAMENTO DOS DADOS")
        df.to_csv(OUTPUT_DIR / 'renewable_energy_data_final.csv', index=False)
        logger.info("‚úÖ Salvo!")

        logger.info("\nüíæ ETAPA 6/6 CARREGAMENTO DOS DADOS NO DATA WAREHOUSE")
        load_data(df)

    except Exception as e:
        logger.error(f"‚ùå Pipeline falhou: {e}")
        logger.error("="*60)
        logger.info("Encerrando pipeline devido ao erro.")
        raise    


if __name__ == "__main__":
    run_pipeline()    